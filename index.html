<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-CEKV88TVGH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-CEKV88TVGH');
  </script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"/>
  <meta http-equiv="Pragma" content="no-cache"/>
  <meta http-equiv="Expires" content="0"/>

  <title>Hyunseung Kim</title>

  <meta name="author" content="Hyunseung Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="8wgyP51oK3iE8mbObQpqqHeMobHOv4KZZgT6vIsB_XM" />

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="pictures/personal_round.png">

</head>

<body>
  <div class="container">
    <div class="row" style="margin-top: 10px;">
      <div class="col-sm-4 name-column" style="min-width: 266px;">
        <p style="text-align:center">
          <name>Hyunseung Kim</name>
        </p>
      </div>
      <div class="col-sm-8 name-column text-right" style="min-width: 266px; margin-top: 10px">
        <p style="text-align:right">
            <a href="https://davian.kaist.ac.kr/"><img src="images/davian_logo.png" alt="logo_uni_tue" class="institute-logo-small"></a>
            &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
            <a href="https://gsai.kaist.ac.kr/?lang=eng/"><img src="images/kaistai_logo.png" alt="logo_uni_tue" class="institute-logo-medium"></a>
        </p>
      </div>
    </div>
    <div class="row common-rows">

      <div class="col-xs-12 col-sm-8 personal-column">
        <p> 
          I am a Deep Learning Researcher at <a href="https://www.krafton.ai/en/">KRAFTON AI</a>, mentored by <a href="https://kangwooklee.com/">Kangwook Lee</a>. Also, I am a Ph.D. candidate at Korea Advanced Institute of Science and Technology (<a href="https://www.kaist.ac.kr/en/">KAIST</a>), advised by <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        </p>
        <p>  
          Currently, I am developing a Co-playable Character (<a href="https://youtu.be/rQuPGUfGMAA?si=_6wBg0NnlLnYLX5J&t=201">CPC</a>), a unique type of in-game character that differs from traditional rule-based Non-Player Character (NPC). I am leading LLM Agent Team and developing the core algorithms for the CPC, which will be integrated into PUBG Battlegrounds.
        </p>
        <p>  
          My primary objective is to develop a generalist agent capable of understanding its environment, making decisions, and autonomously learning from its experiences.
        </p>
        <p style="text-align:center">
          <a href="mailto:mynsng@kaist.ac.kr">Email</a> &nbsp;/&nbsp;
          <a href="data/Hyunseung_Kim_CV.pdf">CV</a> &nbsp;/&nbsp;
          <a href="https://scholar.google.com/citations?user=MPwhSxwAAAAJ&hl=ko">Google Scholar</a> &nbsp;/&nbsp;
          <a href="https://www.linkedin.com/in/hyunseung-kim-64b735231/">Linkedin</a> &nbsp;/&nbsp;
          <a href="https://github.com/mynsng/">Github</a>
        </p>

      </div>
      <div class="col-xs-12 col-sm-4 personal-column" style="margin-top: 30px">
        <img alt="profile photo" src="images/mynsng.jpeg" class="personal-photo">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row section-heading-rows">
      <h4>News</h4>
    </div>
    <div class="row">
      <p>
        <ul>
          <li><b>02.2025. - Present.</b> LLM Agent Team Lead at KRAFTON AI.
          <li><b>01.2025.</b> SimBa is accepted to ICLR 2025 as a spotlight presentation!
          <li><b>09.2024.</b> DoDont is accepted to NeurIPS 2024!
          <li><b>08.2024. - 02.2025.</b> Deep Learning Research Internship at KRAFTON AI.
          <li><b>05.2024.</b> Two papers, Hare&Tortoise and CoIn are accepted to ICML 2024!
          <li><b>09.2023.</b> Two papers, DISCO-DANCE and PLASTIC are accepted to NeurIPS 2023!
        </ul>
      </p>
    </div>
  </div>

  <!-- Work Experience Section -->
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Experience</h4>
    </div>
    <div class="row common-rows">
      <div class="col-xs-12 col-sm-12 personal-column">
        <div style="display: flex; justify-content: space-between; align-items: baseline; margin-bottom: 0;">
          <p style="margin-bottom: 0; flex: 1;">
            <strong style="font-size: 1.2em;">KRAFTON AI</strong> &nbsp;&nbsp;&nbsp;&nbsp;
            <em>Deep Learning Researcher · LLM Agent Team Lead</em>
          </p>
          <span style="white-space: nowrap;">Aug. 2024 - Present</span>
        </div>
        <p style="margin-top: 2px; margin-bottom: 5px; display: flex; justify-content: space-between; align-items: baseline;">
          <span>
            Live Demo of CPC for PUBG at <a href="https://www.ces.tech/">CES 2025</a> in Las Vegas, developed in collaboration with <a href="https://www.nvidia.com/en-us/">NVIDIA</a>.
          </span>
          <span style="white-space: nowrap;">Jan. 2025</span>
        </p>
        <ul style="margin-top: 5px;">
          <li>Led the development of PUBG Ally, Co-playable Character for PUBG.</li>
          <li>Powered by NVIDIA ACE for real-time interaction and strategic gameplay.</li>
          <li>Watch the demo: <a href="https://youtu.be/LNx7wrBfnsw?si=9gMLBxShwrEEZhxc" target="_blank">NVIDIA ACE</a>, <a href="https://youtu.be/ukV-ZUJ1mTo?si=yu40kdxWDV3-AlnC" target="_blank">PUBG Ally</a>, <a href="https://youtube.com/shorts/CSf8wglfhO4?si=XYYPRB8DJAdwrlBX" target="_blank">Live Demo</a></li>
        </ul>
      </div>
    </div>
  </div>
  

  <div class="container">
    <div class="row section-heading-rows">
      <h4>Publications</h4>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
      <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="images/simba.gif" alt="simba" class="paper-images">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
      <br>
      <papertitle>
      SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning
      </papertitle>
      <br>
      <a href="https://joonleesky.github.io/">Hojoon Lee*</a>,
      <a href="https://godnpeter.github.io">Dongyoon Hwang*</a>,
      <a href="https://i-am-proto.github.io">Donghu Kim</a>,
      <strong>Hyunseung Kim</strong>,
      <a href="https://taijunjet.com">Jun Jet Tai</a>,
      <a href="https://kausubbu.github.io">Kaushik Subramanian</a>,
      <a href="https://www.pwurman.org">Peter R. Wurman</a>,
      <a href="https://sites.google.com/site/jaegulchoo">Jaegul Choo</a>,
      <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a>,
      <a href="https://takuseno.github.io/">Takuma Seno</a>.
      <br>
      <em>ICLR'25 (Spotlight)</em>.
      <br>
      <a href="https://sonyresearch.github.io/simba/">project page</a>
      /
      <a href="https://arxiv.org/abs/2410.09754">paper</a>
      <br><br>
      <p style="margin-top: -3%;">   
          Designed network architectures that steer convergence toward simple functions which allows to scale up parameters in RL.
      </p>
    </div>
  </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src='images/preprint2024dodont.png' alt="preprint2024dodont" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ff9aa2">Skill Discovery</span> -->
        <br>
        <a href="http://mynsng.github.io/dodont"></a>
            <papertitle>
                Do’s and Don’ts: Learning Desirable Skills with Instruction Videos
            </papertitle>
        </a>
        <br>
        <strong>Hyunseung Kim</strong>,
          <a href="https://lee15253.github.io">Byungkun Lee</a>,
          <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          <a href="https://godnpeter.github.io">Dongyoon Hwang</a>,
          <a href="https://i-am-proto.github.io/">Donghu Kim</a>,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
        <br>
        <em>NeurIPS'24</em>.
        <br>
        <a href="http://mynsng.github.io/dodont">project page</a>
          /
        <a href="https://arxiv.org/abs/2406.00324">paper</a>
        <br><br>
        <p style="margin-top: -3%;">   
          We present DoDont, an instruction-based skill discovery algorithm designed to combine human intention with unsupervised skill discovery. DoDont learns diverse behvaiors while following the behaviors in "do" videos while avoiding the behaviors in "don't" videos.
        </p>
      </td>
        </p>
      </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src='images/HnT.png' alt="icml2024hnt" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#b5ead7">Plasticity</span> -->
        <br>
          <papertitle>
            Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise Networks
          </papertitle>
        </a>
        <br>
        <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          Hyeonseo Cho,
          <strong>Hyunseung Kim</strong>,
          <a href="https://i-am-proto.github.io/">Donghu Kim</a>,
          <a href="https://dmslab-konkuk.github.io/people/DugkiMin/">Dugki Min</a>,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>,
          <a href="https://clarelyle.com/">Clare Lyle</a>
        <br>
        <em>ICML'24</em>.
        <br>
        <a href="https://arxiv.org/abs/2406.02596">paper</a>
         /
        <a href="https://github.com/dojeon-ai/Hare-Tortoise">code</a>
        <br><br>
        <p style="margin-top: -3%;">   
            To allow the network to continually adapt and generalize, we introduce Hare and Tortoise architecture, 
            inspired by the complementary learning system of the human brain.
        </p>
      </div>
    </div>
    
    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src='images/icml2024coin.png' alt="icml2024coin" class="paper-images">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#f1f1b2">Adaptation</span> -->
        <br>
        <papertitle>
            A Simple Convolution INjector for Vision Transformer: Towards Effective Adaptation in Visuo-Motor Control
        </papertitle>
        <br>
          <a href="https://godnpeter.github.io">Dongyoon Hwang*</a>,
          <a href="https://lee15253.github.io">Byungkun Lee*</a>,
          <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          <strong>Hyunseung Kim</strong>,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
        <br>
        <em>ICML'24</em>.
        <br>
        <a href="data/Coin_paper.pdf">paper</a>
        <br><br>
        <p style="margin-top: -3%;">   
          We introduce CoIn, a lightweight and simple add-on module, which effectively adapts pretrained Vision Transformers for visuo-motor control.
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
      <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src='images/neurips2023disco-dance.png' alt="neurips2023disco-dance" class="paper-images" style="width:90%; margin-left:10%">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
          <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
          <span style="background-color:#ff9aa2">Skill Discovery</span> -->
          <br>
          <!-- <a href="http://mynsng.github.io/discodance"> -->
          <papertitle>
              DISCO-DANCE: Learning to Discover Skills through Guidance
          </papertitle>
          </a>
          <br>
          <strong>Hyunseung Kim*</strong>,
          <a href="https://lee15253.github.io">Byungkun Lee*</a>,
          <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          <a href="https://godnpeter.github.io">Dongyoon Hwang</a>,
          Sejik Park,
          Kyushik Min,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
          <br>
          <em>NeurIPS'23</em>.
          <br>
          <a href="http://mynsng.github.io/discodance">project page</a>
           /
          <a href="https://arxiv.org/abs/2310.20178">paper</a>
           /
          <a href="https://github.com/dojeon-ai/DISCO-DANCE">code</a>
           /
          <a href="https://drive.google.com/file/d/1OzvaebPbe8RIMW8FrH5RdbDLF0QGbX8Z/view?usp=sharing">poster</a>
          <br><br>
          <p style="margin-top: -3%;">   
          We introduce DISCO-DANCE, a skill discovery algorithm focused on learning diverse, task-agnostic behaviors. 
          DISCO-DANCE addresses the common limitation of exploration in skill discovery algorithms through explicit guidance.
          </p>
      </div>
      </div>

    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src='images/neurips2023plastic.png' alt="neurips2023plastic" class="paper-images" style="width:92%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#b5ead7">Plasticity</span> -->
        <br>
        <papertitle>
            PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning
        </papertitle>
        </a>
        <br>
        <a href="https://joonleesky.github.io/">Hojoon Lee*</a>,
          <a href="https://hanseuljo.github.io/">Hanseul Cho*</a>,
          <strong>Hyunseung Kim*</strong>,
          Daehoon Gwak,
          Joonkee Kim,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
          <a href="https://fbsqkd.github.io/">SeYoung Yun</a>,
          <a href="https://chulheeyun.github.io/">Chulhee Yun</a>,
        <br>
        <em>NeurIPS'23</em>.
        <br>
        <a href="https://arxiv.org/abs/2306.10711">paper</a> /
        <a href="https://github.com/dojeon-ai/plastic">code</a> /
        <a href="https://drive.google.com/file/d/1-QeWhom9l7mUt3m7zJV-_DIGMtL7F2Cq/view?usp=sharing">slide</a> /
        <a href="https://drive.google.com/file/d/1-OTP_-rw2x-csjsJ9jH7utuHw9zDxsJc/view?usp=sharing">poster</a> 
        <br><br>
        <p style="margin-top: -3%;">   
            For sample-efficient RL, the agent needs to quickly adapt to various inputs (input plasticity) and outputs (label plasticity). 
            We present PLASTIC, which maintains both input and label plasticity by identifying smooth local minima and preserving gradient flow. 
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src='images/www2022draftrec.png' alt="www2022draftrec" class="paper-images" style="margin-left:8%; width:95%">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <!-- <span style="background-color:#C9D3D8">Data Mining</span>
            <span style="background-color:#e2c7e5">Reinforcement Learning</span>
            <span style="background-color:#c9d2fe">Game</span> -->
            <br>
            <papertitle>
                DraftRec: Personalized Draft Recommendation for Winning in MOBA Games
            </papertitle>
            </a>
            <br>
              <a href="https://joonleesky.github.io/">Hojoon Lee*</a>,
              <a href="https://godnpeter.github.io">Dongyoon Hwang*</a>,
              <strong>Hyunseung Kim</strong>,
              <a href="https://lee15253.github.io">Byungkun Lee</a>,
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
            <br>
            <em>WWW'22</em>.
            <br>
            <a href="https://arxiv.org/abs/2204.12750">paper</a> /
            <a href="https://github.com/dojeon-ai/DraftRec">code</a> /
            <a href="https://drive.google.com/file/d/15L2ZqVutI3xjwJXq9NGbizSZbNsQEXOK/view?usp=sharing">poster</a> /
            <a href="data/www2022draftrec.txt">Bibtex</a>
            <br><br>
            <p style="margin-top: -3%;">                         
                We gathered data from 280,000 matches played by the top 0.3% rank players in Korea for League of Legends. 
                From this, we developed DraftRec, a personalized champion recommendation system aimed at maximizing players' win rates.   
            </p>
        </div>
    </div>

  
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Other activities</h4>
    </div>
    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="images/review.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Reviewing activities
        </papertitle>
        <br>
        <ul>
          <li>Serving as a reviewer for NeurIPS, ICML, ICLR, AISTATS</li>
        </ul>
      </div>
    </div>

    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="images/award.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Awards
        </papertitle>
        <br>
        <ul>
          <li>3rd Place in Computer Science & Engineering, Samsung Humantech Paper, 2025.</li>
          <li>2nd Place, Korea University Graduation Project, 2020, 2021.</li>
        </ul>
      </div>
    </div>
    <br>

    <!-- <br>
    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/talk.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9">
        <papertitle>Talks
        </papertitle>
        <br>
        <ul>
          <li>
            <a href="data/plastic2024talk.pdf">
              Towards Plastic Neural Network
            </a>.
            Sony AI, Tokyo, March 2024.
          </li>
          <li>
            <a href="data/plastic2024talk.pdf">
                Towards Plastic Neural Network
            </a>.
            Konkuk University DMIS Lab, Seoul, Feb 2024.
          </li>
          <li>
            <a href="data/pretrain2023talk.pdf">
                Pre-training for Intelligent Agent
            </a>.
            RL Korea, Seoul, Jan 2024.
          </li>
          <li>
            <a href="data/pretrain2023talk.pdf">
                Pre-training for Intelligent Agent
            </a>.
            Crevisse Partners, Seoul, Dec 2023.</li>
        </ul>
      </div>
    </div>
  </div> -->


  <div class="container">
    <div class="row">
      <div class="col">
        <p style="text-align:right;font-size:small;">
          Template based on <a href="https://joonleesky.github.io/">Hojoon's website</a>.
        </p>
      </div>
    </div>
  </div>
</body>

</html>
