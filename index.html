<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-CEKV88TVGH"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-CEKV88TVGH');
  </script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"/>
  <meta http-equiv="Pragma" content="no-cache"/>
  <meta http-equiv="Expires" content="0"/>

  <title>Hyunseung Kim</title>

  <meta name="author" content="Hyunseung Kim">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="8wgyP51oK3iE8mbObQpqqHeMobHOv4KZZgT6vIsB_XM" />

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="pictures/personal_round.png">

</head>

<body>
  <div class="container">
    <div class="row" style="margin-top: 10px;">
      <div class="col-sm-4 name-column" style="min-width: 266px;">
        <p style="text-align:center">
          <name>Hyunseung Kim</name>
        </p>
      </div>
      <div class="col-sm-8 name-column text-right" style="min-width: 266px; margin-top: 10px">
        <p style="text-align:right">
            <a href="https://davian.kaist.ac.kr/"><img src="images/davian_logo.png" alt="logo_uni_tue" class="institute-logo-small"></a>
            &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
            <a href="https://gsai.kaist.ac.kr/?lang=eng/"><img src="images/kaistai_logo.png" alt="logo_uni_tue" class="institute-logo-medium"></a>
        </p>
      </div>
    </div>
    <div class="row common-rows">

      <div class="col-xs-12 col-sm-8 personal-column">
        <p> 
          I am a Ph.D. student at <a href="https://davian.kaist.ac.kr/">Data and Visual Analytics Lab (DAVIAN-LAB)</a>, advised by <a href="https://sites.google.com/site/jaegulchoo/">Prof. Jaegul Choo</a> at Korea Advanced Institute of Science and Technology (<a href="https://www.kaist.ac.kr/en/">KAIST</a>). I received my B.S. in Computer Science at Korea University in 2021.
        </p>
        <p>  
          Currently, I am a Deep Learning research intern at KRAFTON, mentored by <a href="https://kangwooklee.com/">Kangwook Lee</a>. During my internship, I am developing a Co-playable Character (<a href="https://youtu.be/rQuPGUfGMAA?si=yswUbertxgDbimQR">CPC</a>), a unique type of in-game character that differs from traditional rule-based Non-Player Character (NPC). I am leading the development of the core algorithms for the CPC, which will be integrated into PUBG Battlegrounds.
        </p>
        <p>  
          My primary research objective is to develop a generalist agent capable of understanding its environment, making decisions, and autonomously learning from its experiences. I am currently addressing this challenge by integrating high-level reasoning using foundational models like Vision-Language Models (VLMs) or Large Language Models (LLMs) with low-level control through Reinforcement Learning (RL) or Behavior Cloning (BC).
        </p>
        <p style="text-align:center">
          <a href="mailto:mynsng@kaist.ac.kr">Email</a> &nbsp;/&nbsp;
          <a href="data/Hyunseung_Kim_CV.pdf">CV</a> &nbsp;/&nbsp;
          <a href="https://scholar.google.com/citations?user=MPwhSxwAAAAJ&hl=ko">Google Scholar</a> &nbsp;/&nbsp;
          <a href="https://www.linkedin.com/in/hyunseung-kim-64b735231/">Linkedin</a> &nbsp;/&nbsp;
          <a href="https://github.com/mynsng/">Github</a>
        </p>

      </div>
      <div class="col-xs-12 col-sm-4 personal-column" style="margin-top: 30px">
        <img alt="profile photo" src="images/mynsng.jpeg" class="personal-photo">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row section-heading-rows">
      <h4>News</h4>
    </div>
    <div class="row">
      <p>
        <ul>
          <li><b>09.2024.</b> DoDont is accepted to NeurIPS 2024!
          <li><b>08.2024. - 02.2025.</b> Ongoing Deep Learning Research Internship at KRAFTON.
          <li><b>05.2024.</b> Two papers (Hare&Tortoise and CoIn) are accepted to ICML 2024!
          <li><b>09.2023.</b> Two papers (DISCO-DANCE and PLASTIC) are accepted to NeurIPS 2023!
        </ul>
      </p>
    </div>
  </div>

  <br>
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Publications</h4>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
      <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="images/simba.gif" alt="neurips2024dodont" class="paper-images">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
      <br>
      <papertitle>
      SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning
      </papertitle>
      <br>
      <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
      <a href="https://godnpeter.github.io">Dongyoon Hwang</a>,
      <a href="https://i-am-proto.github.io">Donghu Kim</a>,
      <strong>Hyunseung Kim</strong>,
      <a href="https://taijunjet.com">Jun Jet Tai</a>,
      <a href="https://kausubbu.github.io">Kaushik Subramanian</a>,
      <a href="https://www.pwurman.org">Peter R. Wurman</a>,
      <a href="https://sites.google.com/site/jaegulchoo">Jaegul Choo</a>,
      <a href="https://www.cs.utexas.edu/~pstone/">Peter Stone</a>,
      <a href="https://takuseno.github.io/">Takuma Seno</a>.
      <br>
      <em>Preprint</em>.
      <br>
      <a href="https://sonyresearch.github.io/simba/">project page</a>
      /
      <a href="https://arxiv.org/abs/2410.09754">paper</a>
      <br><br>
      <p style="margin-top: -1%;"> 
          Designed network architectures that steer convergence toward simple functions which allows to scale up parameters in RL.
      </p>
    </div>
  </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src='images/preprint2024dodont.png' alt="preprint2024dodont" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ff9aa2">Skill Discovery</span> -->
        <br>
        <a href="http://mynsng.github.io/dodont"></a>
            <papertitle>
                Do’s and Don’ts: Learning Desirable Skills with Instruction Videos
            </papertitle>
        </a>
        <br>
        <strong>Hyunseung Kim</strong>,
          <a href="https://lee15253.github.io">Byungkun Lee</a>,
          <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          <a href="https://godnpeter.github.io">Dongyoon Hwang</a>,
          <a href="https://i-am-proto.github.io/">Donghu Kim</a>,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
        <br>
        <em>NeurIPS'24</em>.
        <br>
        <a href="http://mynsng.github.io/dodont">project page</a>
          /
        <a href="https://arxiv.org/abs/2406.00324">paper</a>
        <br><br>
        <p style="margin-top: -1%;"> 
          We present DoDont, an instruction-based skill discovery algorithm designed to combine human intention with unsupervised skill discovery. DoDont learns diverse behvaiors while following the behaviors in "do" videos while avoiding the behaviors in "don't" videos.
        </p>
      </td>
        </p>
      </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src='images/HnT.png' alt="icml2024hnt" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#b5ead7">Plasticity</span> -->
        <br>
          <papertitle>
            Slow and Steady Wins the Race: Maintaining Plasticity with Hare and Tortoise Networks
          </papertitle>
        </a>
        <br>
        <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          Hyeonseo Cho,
          <strong>Hyunseung Kim</strong>,
          <a href="https://i-am-proto.github.io/">Donghu Kim</a>,
          <a href="https://dmslab-konkuk.github.io/people/DugkiMin/">Dugki Min</a>,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>,
          <a href="https://clarelyle.com/">Clare Lyle</a>
        <br>
        <em>ICML'24</em>.
        <br>
        <a href="https://arxiv.org/abs/2406.02596">paper</a>
         /
        <a href="https://github.com/dojeon-ai/Hare-Tortoise">code</a>
        <br><br>
        <p style="margin-top: -1%;"> 
            To allow the network to continually adapt and generalize, we introduce Hare and Tortoise architecture, 
            inspired by the complementary learning system of the human brain.
        </p>
      </div>
    </div>
    
    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src='images/icml2024coin.png' alt="icml2024coin" class="paper-images">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#f1f1b2">Adaptation</span> -->
        <br>
        <papertitle>
            A Simple Convolution INjector for Vision Transformer: Towards Effective Adaptation in Visuo-Motor Control
        </papertitle>
        <br>
          <a href="https://godnpeter.github.io">Dongyoon Hwang*</a>,
          <a href="https://lee15253.github.io">Byungkun Lee*</a>,
          <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          <strong>Hyunseung Kim</strong>,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
        <br>
        <em>ICML'24</em>.
        <br>
        <a href="data/Coin_paper.pdf">paper</a>
        <br><br>
        <p style="margin-top: -1%;"> 
          We introduce CoIn, a lightweight and simple add-on module, which effectively adapts pretrained Vision Transformers for visuo-motor control.
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
      <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src='images/neurips2023disco-dance.png' alt="neurips2023disco-dance" class="paper-images" style="width:90%; margin-left:10%">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
          <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
          <span style="background-color:#ff9aa2">Skill Discovery</span> -->
          <br>
          <!-- <a href="http://mynsng.github.io/discodance"> -->
          <papertitle>
              DISCO-DANCE: Learning to Discover Skills through Guidance
          </papertitle>
          </a>
          <br>
          <strong>Hyunseung Kim*</strong>,
          <a href="https://lee15253.github.io">Byungkun Lee*</a>,
          <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
          <a href="https://godnpeter.github.io">Dongyoon Hwang</a>,
          Sejik Park,
          Kyushik Min,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
          <br>
          <em>NeurIPS'23</em>.
          <br>
          <a href="http://mynsng.github.io/discodance">project page</a>
           /
          <a href="https://arxiv.org/abs/2310.20178">paper</a>
           /
          <a href="https://github.com/dojeon-ai/DISCO-DANCE">code</a>
           /
          <a href="https://drive.google.com/file/d/1OzvaebPbe8RIMW8FrH5RdbDLF0QGbX8Z/view?usp=sharing">poster</a>
          <br><br>
          <p style="margin-top: -1%;"> 
          We introduce DISCO-DANCE, a skill discovery algorithm focused on learning diverse, task-agnostic behaviors. 
          DISCO-DANCE addresses the common limitation of exploration in skill discovery algorithms through explicit guidance.
          </p>
      </div>
      </div>

    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src='images/neurips2023plastic.png' alt="neurips2023plastic" class="paper-images" style="width:92%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <!-- <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#b5ead7">Plasticity</span> -->
        <br>
        <papertitle>
            PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning
        </papertitle>
        </a>
        <br>
        <a href="https://joonleesky.github.io/">Hojoon Lee*</a>,
          <a href="https://hanseuljo.github.io/">Hanseul Cho*</a>,
          <strong>Hyunseung Kim*</strong>,
          Daehoon Gwak,
          Joonkee Kim,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
          <a href="https://fbsqkd.github.io/">SeYoung Yun</a>,
          <a href="https://chulheeyun.github.io/">Chulhee Yun</a>,
        <br>
        <em>NeurIPS'23</em>.
        <br>
        <a href="https://arxiv.org/abs/2306.10711">paper</a> /
        <a href="https://github.com/dojeon-ai/plastic">code</a> /
        <a href="https://drive.google.com/file/d/1-QeWhom9l7mUt3m7zJV-_DIGMtL7F2Cq/view?usp=sharing">slide</a> /
        <a href="https://drive.google.com/file/d/1-OTP_-rw2x-csjsJ9jH7utuHw9zDxsJc/view?usp=sharing">poster</a> /
        <br><br>
        <p style="margin-top: -1%;"> 
            For sample-efficient RL, the agent needs to quickly adapt to various inputs (input plasticity) and outputs (label plasticity). 
            We present PLASTIC, which maintains both input and label plasticity by identifying smooth local minima and preserving gradient flow. 
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src='images/www2022draftrec.png' alt="www2022draftrec" class="paper-images" style="margin-left:8%; width:95%">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <!-- <span style="background-color:#C9D3D8">Data Mining</span>
            <span style="background-color:#e2c7e5">Reinforcement Learning</span>
            <span style="background-color:#c9d2fe">Game</span> -->
            <br>
            <papertitle>
                DraftRec: Personalized Draft Recommendation for Winning in MOBA Games
            </papertitle>
            </a>
            <br>
              <a href="https://joonleesky.github.io/">Hojoon Lee*</a>,
              <a href="https://godnpeter.github.io">Dongyoon Hwang*</a>,
              <strong>Hyunseung Kim</strong>,
              <a href="https://lee15253.github.io">Byungkun Lee</a>,
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>
            <br>
            <em>WWW'22</em>.
            <br>
            <a href="https://arxiv.org/abs/2204.12750">paper</a> /
            <a href="https://github.com/dojeon-ai/DraftRec">code</a> /
            <a href="https://drive.google.com/file/d/15L2ZqVutI3xjwJXq9NGbizSZbNsQEXOK/view?usp=sharing">poster</a> /
            <a href="data/www2022draftrec.txt">Bibtex</a>
            <br><br>
            <p style="margin-top: -1%;">                         
                We gathered data from 280,000 matches played by the top 0.3% rank players in Korea for League of Legends. 
                From this, we developed DraftRec, a personalized champion recommendation system aimed at maximizing players' win rates.   
            </p>
        </div>
    </div>

  <!-- <br>
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Other activities</h4>
    </div>
    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/review.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Reviewing activities
        </papertitle>
        <br>
        <ul>
          <li>Serving as a reviewer for NeurIPS'23, ICML'24, ICLR'24.</li>
        </ul>
      </div>
    </div>

    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/award.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Awards
        </papertitle>
        <br>
        <ul>
          <li>Travel Award ($3,000 as awards), Crevisse Partners, 2023.</li>
          <li>SIGIR Best Short Paper Honorable Mention, 2022.</li>
          <li>Korea Government Full Scholarship ($10,000 per year), 2020, 2021.</li>
          <li>Silver Prize ($2,000 as awards), Korea University Graduation Project, 2019.</li>
          <li>College Scholarship ($4,000 as awards), Seongnam Scholarship Foundation, 2017.</li>
          <li><a href="https://www.army.mil/article/180976/area_ii_chapter_sergeant_audie_murphy_clubgeneral_paik_leadership_award_induction_ceremony">General Paik Sun Yup Leadership Award</a>
            , LTG Thomas.S.Vandal, U.S Army, 2017.</li>
        </ul>
      </div>
    </div>
    <br>

    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/talk.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9">
        <papertitle>Talks
        </papertitle>
        <br>
        <ul>
          <li>
            <a href="data/plastic2024talk.pdf">
              Towards Plastic Neural Network
            </a>.
            Sony AI, Tokyo, March 2024.
          </li>
          <li>
            <a href="data/plastic2024talk.pdf">
                Towards Plastic Neural Network
            </a>.
            Konkuk University DMIS Lab, Seoul, Feb 2024.
          </li>
          <li>
            <a href="data/pretrain2023talk.pdf">
                Pre-training for Intelligent Agent
            </a>.
            RL Korea, Seoul, Jan 2024.
          </li>
          <li>
            <a href="data/pretrain2023talk.pdf">
                Pre-training for Intelligent Agent
            </a>.
            Crevisse Partners, Seoul, Dec 2023.</li>
        </ul>
      </div>
    </div>
  </div> -->


  <div class="container">
    <div class="row">
      <div class="col">
        <p style="text-align:right;font-size:small;">
          Template based on <a href="https://joonleesky.github.io/">Hojoon's website</a>.
        </p>
      </div>
    </div>
  </div>
</body>

</html>
